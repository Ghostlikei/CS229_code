{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS229 Problem Set 2: Supervised Learning II"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1: Logistic regression: Training Stability\n",
    "\n",
    "- Aimed at debugging machine learning algorithms\n",
    "\n",
    "The first part of the code went wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training model on data set A ====\n",
      "Finished 10000 iterations with grad=[ 4.15154546e-08 -4.27822247e-08 -4.08456455e-08]\n",
      "Finished 20000 iterations with grad=[ 3.06367605e-12 -3.15717618e-12 -3.01431651e-12]\n",
      "Finished 30000 iterations with grad=[ 2.01423176e-16 -2.86463533e-16 -1.89141759e-16]\n",
      "Converged in 30380 iterations\n",
      "\n",
      "==== Training model on data set B ====\n",
      "Finished 10000 iterations with grad=[ 0.00019399 -0.00019355 -0.00019461]\n",
      "Finished 20000 iterations with grad=[ 0.00012541 -0.00012529 -0.0001257 ]\n",
      "Finished 30000 iterations with grad=[ 9.60445104e-05 -9.60553587e-05 -9.61981110e-05]\n",
      "Finished 40000 iterations with grad=[ 7.90651647e-05 -7.91523106e-05 -7.91443884e-05]\n",
      "Finished 50000 iterations with grad=[ 6.78328688e-05 -6.79700947e-05 -6.78680755e-05]\n",
      "Finished 60000 iterations with grad=[ 5.97905761e-05 -5.99622968e-05 -5.97981756e-05]\n",
      "Finished 70000 iterations with grad=[ 5.37193268e-05 -5.39154728e-05 -5.37089335e-05]\n",
      "Finished 80000 iterations with grad=[ 4.89573832e-05 -4.91710659e-05 -4.89349658e-05]\n",
      "Finished 90000 iterations with grad=[ 4.51121714e-05 -4.53384732e-05 -4.50816023e-05]\n",
      "Finished 100000 iterations with grad=[ 4.19351585e-05 -4.21704526e-05 -4.18990387e-05]\n",
      "Finished 110000 iterations with grad=[ 3.92609485e-05 -3.95024927e-05 -3.92210742e-05]\n",
      "Finished 120000 iterations with grad=[ 3.69750168e-05 -3.72206979e-05 -3.69326555e-05]\n",
      "Finished 130000 iterations with grad=[ 3.49954536e-05 -3.52436199e-05 -3.49515156e-05]\n",
      "Finished 140000 iterations with grad=[ 3.32620741e-05 -3.35114213e-05 -3.32172218e-05]\n",
      "Finished 150000 iterations with grad=[ 3.17296345e-05 -3.19791254e-05 -3.16843546e-05]\n",
      "Finished 160000 iterations with grad=[ 3.03634490e-05 -3.06122555e-05 -3.03181014e-05]\n",
      "Finished 170000 iterations with grad=[ 2.91364685e-05 -2.93839282e-05 -2.90913200e-05]\n",
      "Finished 180000 iterations with grad=[ 2.80272810e-05 -2.82728648e-05 -2.79825294e-05]\n",
      "Finished 190000 iterations with grad=[ 2.70187108e-05 -2.72619975e-05 -2.69745020e-05]\n",
      "Finished 200000 iterations with grad=[ 2.60968164e-05 -2.63374724e-05 -2.60532566e-05]\n",
      "Finished 210000 iterations with grad=[ 2.52501600e-05 -2.54879241e-05 -2.52073258e-05]\n",
      "Finished 220000 iterations with grad=[ 2.44692680e-05 -2.47039383e-05 -2.44272125e-05]\n",
      "Finished 230000 iterations with grad=[ 2.37462239e-05 -2.39776478e-05 -2.37049827e-05]\n",
      "Finished 240000 iterations with grad=[ 2.30743602e-05 -2.33024253e-05 -2.30339548e-05]\n",
      "Finished 250000 iterations with grad=[ 2.24480194e-05 -2.26726471e-05 -2.24084608e-05]\n",
      "Finished 260000 iterations with grad=[ 2.18623687e-05 -2.20835083e-05 -2.18236597e-05]\n",
      "Finished 270000 iterations with grad=[ 2.13132541e-05 -2.15308777e-05 -2.12753909e-05]\n",
      "Finished 280000 iterations with grad=[ 2.07970840e-05 -2.10111828e-05 -2.07600582e-05]\n",
      "Finished 290000 iterations with grad=[ 2.03107365e-05 -2.05213175e-05 -2.02745359e-05]\n",
      "Finished 300000 iterations with grad=[ 1.98514844e-05 -2.00585672e-05 -1.98160940e-05]\n",
      "Finished 310000 iterations with grad=[ 1.94169339e-05 -1.96205487e-05 -1.93823366e-05]\n",
      "Finished 320000 iterations with grad=[ 1.90049745e-05 -1.92051600e-05 -1.89711519e-05]\n",
      "Finished 330000 iterations with grad=[ 1.86137381e-05 -1.88105397e-05 -1.85806706e-05]\n",
      "Finished 340000 iterations with grad=[ 1.82415643e-05 -1.84350330e-05 -1.82092317e-05]\n",
      "Finished 350000 iterations with grad=[ 1.78869723e-05 -1.80771632e-05 -1.78553542e-05]\n",
      "Finished 360000 iterations with grad=[ 1.75486366e-05 -1.77356081e-05 -1.75177123e-05]\n",
      "Finished 370000 iterations with grad=[ 1.72253669e-05 -1.74091799e-05 -1.71951158e-05]\n",
      "Finished 380000 iterations with grad=[ 1.69160910e-05 -1.70968081e-05 -1.68864929e-05]\n",
      "Finished 390000 iterations with grad=[ 1.66198405e-05 -1.67975252e-05 -1.65908751e-05]\n",
      "Finished 400000 iterations with grad=[ 1.63357379e-05 -1.65104545e-05 -1.63073855e-05]\n",
      "Finished 410000 iterations with grad=[ 1.60629860e-05 -1.62347992e-05 -1.60352275e-05]\n",
      "Finished 420000 iterations with grad=[ 1.58008592e-05 -1.59698333e-05 -1.57736757e-05]\n",
      "Finished 430000 iterations with grad=[ 1.55486949e-05 -1.57148940e-05 -1.55220682e-05]\n",
      "Finished 440000 iterations with grad=[ 1.53058870e-05 -1.54693745e-05 -1.52797994e-05]\n",
      "Finished 450000 iterations with grad=[ 1.50718797e-05 -1.52327185e-05 -1.50463141e-05]\n",
      "Finished 460000 iterations with grad=[ 1.48461625e-05 -1.50044142e-05 -1.48211024e-05]\n",
      "Finished 470000 iterations with grad=[ 1.46282654e-05 -1.47839906e-05 -1.46036946e-05]\n",
      "Finished 480000 iterations with grad=[ 1.44177546e-05 -1.45710129e-05 -1.43936578e-05]\n",
      "Finished 490000 iterations with grad=[ 1.42142296e-05 -1.43650793e-05 -1.41905918e-05]\n",
      "Finished 500000 iterations with grad=[ 1.40173196e-05 -1.41658177e-05 -1.39941264e-05]\n",
      "Finished 510000 iterations with grad=[ 1.38266806e-05 -1.39728828e-05 -1.38039182e-05]\n",
      "Finished 520000 iterations with grad=[ 1.36419934e-05 -1.37859540e-05 -1.36196483e-05]\n",
      "Finished 530000 iterations with grad=[ 1.34629608e-05 -1.36047329e-05 -1.34410204e-05]\n",
      "Finished 540000 iterations with grad=[ 1.32893063e-05 -1.34289415e-05 -1.32677581e-05]\n",
      "Finished 550000 iterations with grad=[ 1.31207717e-05 -1.32583203e-05 -1.30996038e-05]\n",
      "Finished 560000 iterations with grad=[ 1.29571159e-05 -1.30926269e-05 -1.29363170e-05]\n",
      "Finished 570000 iterations with grad=[ 1.27981136e-05 -1.29316345e-05 -1.27776725e-05]\n",
      "Finished 580000 iterations with grad=[ 1.26435535e-05 -1.27751306e-05 -1.26234597e-05]\n",
      "Finished 590000 iterations with grad=[ 1.24932376e-05 -1.26229160e-05 -1.24734809e-05]\n",
      "Finished 600000 iterations with grad=[ 1.23469801e-05 -1.24748034e-05 -1.23275506e-05]\n",
      "Finished 610000 iterations with grad=[ 1.22046063e-05 -1.23306170e-05 -1.21854946e-05]\n",
      "Finished 620000 iterations with grad=[ 1.20659518e-05 -1.21901913e-05 -1.20471489e-05]\n",
      "Finished 630000 iterations with grad=[ 1.19308619e-05 -1.20533701e-05 -1.19123589e-05]\n",
      "Finished 640000 iterations with grad=[ 1.17991906e-05 -1.19200066e-05 -1.17809792e-05]\n",
      "Finished 650000 iterations with grad=[ 1.16708003e-05 -1.17899617e-05 -1.16528723e-05]\n",
      "Finished 660000 iterations with grad=[ 1.15455607e-05 -1.16631044e-05 -1.15279084e-05]\n",
      "Finished 670000 iterations with grad=[ 1.14233491e-05 -1.15393106e-05 -1.14059649e-05]\n",
      "Finished 680000 iterations with grad=[ 1.13040488e-05 -1.14184628e-05 -1.12869255e-05]\n",
      "Finished 690000 iterations with grad=[ 1.11875498e-05 -1.13004498e-05 -1.11706803e-05]\n",
      "Finished 700000 iterations with grad=[ 1.10737475e-05 -1.11851662e-05 -1.10571251e-05]\n",
      "Finished 710000 iterations with grad=[ 1.09625427e-05 -1.10725118e-05 -1.09461610e-05]\n",
      "Finished 720000 iterations with grad=[ 1.08538413e-05 -1.09623915e-05 -1.08376940e-05]\n",
      "Finished 730000 iterations with grad=[ 1.07475539e-05 -1.08547151e-05 -1.07316349e-05]\n",
      "Finished 740000 iterations with grad=[ 1.06435953e-05 -1.07493967e-05 -1.06278989e-05]\n",
      "Finished 750000 iterations with grad=[ 1.05418848e-05 -1.06463544e-05 -1.05264052e-05]\n",
      "Finished 760000 iterations with grad=[ 1.04423451e-05 -1.05455105e-05 -1.04270771e-05]\n",
      "Finished 770000 iterations with grad=[ 1.03449029e-05 -1.04467906e-05 -1.03298411e-05]\n",
      "Finished 780000 iterations with grad=[ 1.02494881e-05 -1.03501240e-05 -1.02346274e-05]\n",
      "Finished 790000 iterations with grad=[ 1.01560339e-05 -1.02554431e-05 -1.01413695e-05]\n",
      "Finished 800000 iterations with grad=[ 1.00644766e-05 -1.01626836e-05 -1.00500037e-05]\n",
      "Finished 810000 iterations with grad=[ 9.97475505e-06 -1.00717836e-05 -9.96046918e-06]\n",
      "Finished 820000 iterations with grad=[ 9.88681115e-06 -9.98268441e-06 -9.87270785e-06]\n",
      "Finished 830000 iterations with grad=[ 9.80058915e-06 -9.89532957e-06 -9.78666416e-06]\n",
      "Finished 840000 iterations with grad=[ 9.71603573e-06 -9.80966518e-06 -9.70228491e-06]\n",
      "Finished 850000 iterations with grad=[ 9.63309984e-06 -9.72563958e-06 -9.61951920e-06]\n",
      "Finished 860000 iterations with grad=[ 9.55173257e-06 -9.64320330e-06 -9.53831824e-06]\n",
      "Finished 870000 iterations with grad=[ 9.47188704e-06 -9.56230889e-06 -9.45863527e-06]\n",
      "Finished 880000 iterations with grad=[ 9.39351830e-06 -9.48291087e-06 -9.38042547e-06]\n",
      "Finished 890000 iterations with grad=[ 9.31658321e-06 -9.40496557e-06 -9.30364581e-06]\n",
      "Finished 900000 iterations with grad=[ 9.24104036e-06 -9.32843110e-06 -9.22825499e-06]\n",
      "Finished 910000 iterations with grad=[ 9.16685000e-06 -9.25326719e-06 -9.15421336e-06]\n",
      "Finished 920000 iterations with grad=[ 9.09397391e-06 -9.17943517e-06 -9.08148281e-06]\n",
      "Finished 930000 iterations with grad=[ 9.02237536e-06 -9.10689786e-06 -9.01002671e-06]\n",
      "Finished 940000 iterations with grad=[ 8.95201905e-06 -9.03561949e-06 -8.93980984e-06]\n",
      "Finished 950000 iterations with grad=[ 8.88287098e-06 -8.96556566e-06 -8.87079830e-06]\n",
      "Finished 960000 iterations with grad=[ 8.81489845e-06 -8.89670324e-06 -8.80295947e-06]\n",
      "Finished 970000 iterations with grad=[ 8.74806998e-06 -8.82900035e-06 -8.73626195e-06]\n",
      "Finished 980000 iterations with grad=[ 8.68235521e-06 -8.76242625e-06 -8.67067548e-06]\n",
      "Finished 990000 iterations with grad=[ 8.61772493e-06 -8.69695134e-06 -8.60617091e-06]\n",
      "Finished 1000000 iterations with grad=[ 8.55415094e-06 -8.63254707e-06 -8.54272013e-06]\n",
      "Finished 1010000 iterations with grad=[ 8.49160607e-06 -8.56918590e-06 -8.48029602e-06]\n",
      "Finished 1020000 iterations with grad=[ 8.43006410e-06 -8.50684129e-06 -8.41887245e-06]\n",
      "Finished 1030000 iterations with grad=[ 8.36949972e-06 -8.44548758e-06 -8.35842416e-06]\n",
      "Finished 1040000 iterations with grad=[ 8.30988851e-06 -8.38510004e-06 -8.29892680e-06]\n",
      "Finished 1050000 iterations with grad=[ 8.25120686e-06 -8.32565474e-06 -8.24035684e-06]\n",
      "Finished 1060000 iterations with grad=[ 8.19343199e-06 -8.26712860e-06 -8.18269153e-06]\n",
      "Finished 1070000 iterations with grad=[ 8.13654186e-06 -8.20949929e-06 -8.12590891e-06]\n",
      "Finished 1080000 iterations with grad=[ 8.08051519e-06 -8.15274524e-06 -8.06998774e-06]\n",
      "Finished 1090000 iterations with grad=[ 8.02533136e-06 -8.09684557e-06 -8.01490748e-06]\n",
      "Finished 1100000 iterations with grad=[ 7.97097047e-06 -8.04178009e-06 -7.96064825e-06]\n",
      "Finished 1110000 iterations with grad=[ 7.91741323e-06 -7.98752926e-06 -7.90719083e-06]\n",
      "Finished 1120000 iterations with grad=[ 7.86464099e-06 -7.93407418e-06 -7.85451662e-06]\n",
      "Finished 1130000 iterations with grad=[ 7.81263568e-06 -7.88139654e-06 -7.80260758e-06]\n",
      "Finished 1140000 iterations with grad=[ 7.76137980e-06 -7.82947860e-06 -7.75144627e-06]\n",
      "Finished 1150000 iterations with grad=[ 7.71085640e-06 -7.77830317e-06 -7.70101578e-06]\n",
      "Finished 1160000 iterations with grad=[ 7.66104906e-06 -7.72785361e-06 -7.65129973e-06]\n",
      "Finished 1170000 iterations with grad=[ 7.61194184e-06 -7.67811377e-06 -7.60228223e-06]\n",
      "Finished 1180000 iterations with grad=[ 7.56351932e-06 -7.62906802e-06 -7.55394789e-06]\n",
      "Finished 1190000 iterations with grad=[ 7.51576653e-06 -7.58070116e-06 -7.50628178e-06]\n",
      "Finished 1200000 iterations with grad=[ 7.46866893e-06 -7.53299848e-06 -7.45926940e-06]\n",
      "Finished 1210000 iterations with grad=[ 7.42221243e-06 -7.48594569e-06 -7.41289669e-06]\n",
      "Finished 1220000 iterations with grad=[ 7.37638335e-06 -7.43952891e-06 -7.36715002e-06]\n",
      "Finished 1230000 iterations with grad=[ 7.33116842e-06 -7.39373469e-06 -7.32201614e-06]\n",
      "Finished 1240000 iterations with grad=[ 7.28655473e-06 -7.34854996e-06 -7.27748218e-06]\n",
      "Finished 1250000 iterations with grad=[ 7.24252977e-06 -7.30396201e-06 -7.23353565e-06]\n",
      "Finished 1260000 iterations with grad=[ 7.19908135e-06 -7.25995850e-06 -7.19016441e-06]\n",
      "Finished 1270000 iterations with grad=[ 7.15619767e-06 -7.21652745e-06 -7.14735667e-06]\n",
      "Finished 1280000 iterations with grad=[ 7.11386722e-06 -7.17365720e-06 -7.10510096e-06]\n",
      "Finished 1290000 iterations with grad=[ 7.07207883e-06 -7.13133643e-06 -7.06338613e-06]\n",
      "Finished 1300000 iterations with grad=[ 7.03082163e-06 -7.08955411e-06 -7.02220136e-06]\n",
      "Finished 1310000 iterations with grad=[ 6.99008506e-06 -7.04829953e-06 -6.98153608e-06]\n",
      "Finished 1320000 iterations with grad=[ 6.94985884e-06 -7.00756228e-06 -6.94138006e-06]\n",
      "Finished 1330000 iterations with grad=[ 6.91013296e-06 -6.96733220e-06 -6.90172332e-06]\n",
      "Finished 1340000 iterations with grad=[ 6.87089768e-06 -6.92759942e-06 -6.86255613e-06]\n",
      "Finished 1350000 iterations with grad=[ 6.83214354e-06 -6.88835434e-06 -6.82386905e-06]\n",
      "Finished 1360000 iterations with grad=[ 6.79386131e-06 -6.84958760e-06 -6.78565288e-06]\n",
      "Finished 1370000 iterations with grad=[ 6.75604199e-06 -6.81129009e-06 -6.74789865e-06]\n",
      "Finished 1380000 iterations with grad=[ 6.71867684e-06 -6.77345293e-06 -6.71059763e-06]\n",
      "Finished 1390000 iterations with grad=[ 6.68175733e-06 -6.73606749e-06 -6.67374131e-06]\n",
      "Finished 1400000 iterations with grad=[ 6.64527517e-06 -6.69912533e-06 -6.63732142e-06]\n",
      "Finished 1410000 iterations with grad=[ 6.60922224e-06 -6.66261826e-06 -6.60132988e-06]\n",
      "Finished 1420000 iterations with grad=[ 6.57359066e-06 -6.62653826e-06 -6.56575881e-06]\n",
      "Finished 1430000 iterations with grad=[ 6.53837274e-06 -6.59087754e-06 -6.53060054e-06]\n",
      "Finished 1440000 iterations with grad=[ 6.50356098e-06 -6.55562849e-06 -6.49584758e-06]\n",
      "Finished 1450000 iterations with grad=[ 6.46914807e-06 -6.52078370e-06 -6.46149265e-06]\n",
      "Finished 1460000 iterations with grad=[ 6.43512685e-06 -6.48633592e-06 -6.42752862e-06]\n",
      "Finished 1470000 iterations with grad=[ 6.40149039e-06 -6.45227811e-06 -6.39394855e-06]\n",
      "Finished 1480000 iterations with grad=[ 6.36823188e-06 -6.41860337e-06 -6.36074566e-06]\n",
      "Finished 1490000 iterations with grad=[ 6.33534469e-06 -6.38530497e-06 -6.32791333e-06]\n",
      "Finished 1500000 iterations with grad=[ 6.30282236e-06 -6.35237637e-06 -6.29544512e-06]\n",
      "Finished 1510000 iterations with grad=[ 6.27065857e-06 -6.31981116e-06 -6.26333473e-06]\n",
      "Finished 1520000 iterations with grad=[ 6.23884716e-06 -6.28760308e-06 -6.23157599e-06]\n",
      "Finished 1530000 iterations with grad=[ 6.20738209e-06 -6.25574602e-06 -6.20016291e-06]\n",
      "Finished 1540000 iterations with grad=[ 6.17625749e-06 -6.22423402e-06 -6.16908961e-06]\n",
      "Finished 1550000 iterations with grad=[ 6.14546762e-06 -6.19306126e-06 -6.13835036e-06]\n",
      "Finished 1560000 iterations with grad=[ 6.11500685e-06 -6.16222204e-06 -6.10793957e-06]\n",
      "Finished 1570000 iterations with grad=[ 6.08486971e-06 -6.13171081e-06 -6.07785176e-06]\n",
      "Finished 1580000 iterations with grad=[ 6.05505084e-06 -6.10152212e-06 -6.04808158e-06]\n",
      "Finished 1590000 iterations with grad=[ 6.02554499e-06 -6.07165066e-06 -6.01862381e-06]\n",
      "Finished 1600000 iterations with grad=[ 5.99634705e-06 -6.04209125e-06 -5.98947333e-06]\n",
      "Finished 1610000 iterations with grad=[ 5.96745201e-06 -6.01283880e-06 -5.96062516e-06]\n",
      "Finished 1620000 iterations with grad=[ 5.93885497e-06 -5.98388835e-06 -5.93207440e-06]\n",
      "Finished 1630000 iterations with grad=[ 5.91055114e-06 -5.95523504e-06 -5.90381629e-06]\n",
      "Finished 1640000 iterations with grad=[ 5.88253585e-06 -5.92687413e-06 -5.87584614e-06]\n",
      "Finished 1650000 iterations with grad=[ 5.85480450e-06 -5.89880097e-06 -5.84815938e-06]\n",
      "Finished 1660000 iterations with grad=[ 5.82735262e-06 -5.87101101e-06 -5.82075156e-06]\n",
      "Finished 1670000 iterations with grad=[ 5.80017583e-06 -5.84349982e-06 -5.79361828e-06]\n",
      "Finished 1680000 iterations with grad=[ 5.77326983e-06 -5.81626303e-06 -5.76675526e-06]\n",
      "Finished 1690000 iterations with grad=[ 5.74663041e-06 -5.78929638e-06 -5.74015833e-06]\n",
      "Finished 1700000 iterations with grad=[ 5.72025348e-06 -5.76259572e-06 -5.71382336e-06]\n",
      "Finished 1710000 iterations with grad=[ 5.69413499e-06 -5.73615695e-06 -5.68774636e-06]\n",
      "Finished 1720000 iterations with grad=[ 5.66827103e-06 -5.70997608e-06 -5.66192338e-06]\n",
      "Finished 1730000 iterations with grad=[ 5.64265771e-06 -5.68404920e-06 -5.63635057e-06]\n",
      "Finished 1740000 iterations with grad=[ 5.61729127e-06 -5.65837247e-06 -5.61102417e-06]\n",
      "Finished 1750000 iterations with grad=[ 5.59216800e-06 -5.63294215e-06 -5.58594048e-06]\n",
      "Finished 1760000 iterations with grad=[ 5.56728428e-06 -5.60775456e-06 -5.56109588e-06]\n",
      "Finished 1770000 iterations with grad=[ 5.54263655e-06 -5.58280609e-06 -5.53648683e-06]\n",
      "Finished 1780000 iterations with grad=[ 5.51822133e-06 -5.55809321e-06 -5.51210985e-06]\n",
      "Finished 1790000 iterations with grad=[ 5.49403522e-06 -5.53361247e-06 -5.48796155e-06]\n",
      "Finished 1800000 iterations with grad=[ 5.47007487e-06 -5.50936048e-06 -5.46403858e-06]\n",
      "Finished 1810000 iterations with grad=[ 5.44633700e-06 -5.48533391e-06 -5.44033768e-06]\n",
      "Finished 1820000 iterations with grad=[ 5.42281841e-06 -5.46152951e-06 -5.41685564e-06]\n",
      "Finished 1830000 iterations with grad=[ 5.39951594e-06 -5.43794410e-06 -5.39358933e-06]\n",
      "Finished 1840000 iterations with grad=[ 5.37642651e-06 -5.41457453e-06 -5.37053566e-06]\n",
      "Finished 1850000 iterations with grad=[ 5.35354709e-06 -5.39141774e-06 -5.34769161e-06]\n",
      "Finished 1860000 iterations with grad=[ 5.33087471e-06 -5.36847072e-06 -5.32505422e-06]\n",
      "Finished 1870000 iterations with grad=[ 5.30840647e-06 -5.34573053e-06 -5.30262059e-06]\n",
      "Finished 1880000 iterations with grad=[ 5.28613951e-06 -5.32319426e-06 -5.28038786e-06]\n",
      "Finished 1890000 iterations with grad=[ 5.26407102e-06 -5.30085907e-06 -5.25835325e-06]\n",
      "Finished 1900000 iterations with grad=[ 5.24219826e-06 -5.27872219e-06 -5.23651401e-06]\n",
      "Finished 1910000 iterations with grad=[ 5.22051854e-06 -5.25678087e-06 -5.21486745e-06]\n",
      "Finished 1920000 iterations with grad=[ 5.19902921e-06 -5.23503244e-06 -5.19341093e-06]\n",
      "Finished 1930000 iterations with grad=[ 5.17772767e-06 -5.21347427e-06 -5.17214186e-06]\n",
      "Finished 1940000 iterations with grad=[ 5.15661137e-06 -5.19210376e-06 -5.15105770e-06]\n",
      "Finished 1950000 iterations with grad=[ 5.13567782e-06 -5.17091839e-06 -5.13015595e-06]\n",
      "Finished 1960000 iterations with grad=[ 5.11492456e-06 -5.14991567e-06 -5.10943417e-06]\n",
      "Finished 1970000 iterations with grad=[ 5.09434918e-06 -5.12909315e-06 -5.08888994e-06]\n",
      "Finished 1980000 iterations with grad=[ 5.07394931e-06 -5.10844844e-06 -5.06852092e-06]\n",
      "Finished 1990000 iterations with grad=[ 5.05372264e-06 -5.08797917e-06 -5.04832477e-06]\n",
      "Finished 2000000 iterations with grad=[ 5.03366687e-06 -5.06768305e-06 -5.02829922e-06]\n",
      "After 2000000 iterations, the algorithm still not converge!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    xrange\n",
    "except NameError:\n",
    "    xrange = range\n",
    "\n",
    "def add_intercept(X_):\n",
    "    m, n = X_.shape\n",
    "    X = np.zeros((m, n + 1))\n",
    "    X[:, 0] = 1\n",
    "    X[:, 1:] = X_\n",
    "    return X\n",
    "\n",
    "def load_data(filename):\n",
    "    D = np.loadtxt(filename)\n",
    "    Y = D[:, 0]\n",
    "    X = D[:, 1:]\n",
    "    return add_intercept(X), Y\n",
    "\n",
    "def calc_grad(X, Y, theta):\n",
    "    m, n = X.shape\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    margins = Y * X.dot(theta)\n",
    "    probs = 1. / (1 + np.exp(margins))\n",
    "    grad = -(1./m) * (X.T.dot(probs * Y))\n",
    "\n",
    "    return grad\n",
    "\n",
    "def logistic_regression(X, Y, rate = 10):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    learning_rate = rate\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        prev_theta = theta\n",
    "        grad = calc_grad(X, Y, theta)\n",
    "        theta = theta  - learning_rate * (grad)\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Finished {i} iterations with grad={grad}\")\n",
    "        if np.linalg.norm(prev_theta - theta) < 1e-15:\n",
    "            print('Converged in %d iterations' % i)\n",
    "            break\n",
    "        if i > 2000000:\n",
    "            print(\"After 2000000 iterations, the algorithm still not converge!\")\n",
    "            break\n",
    "    return\n",
    "\n",
    "print('==== Training model on data set A ====')\n",
    "Xa, Ya = load_data('data_a.txt')\n",
    "logistic_regression(Xa, Ya)\n",
    "\n",
    "print('\\n==== Training model on data set B ====')\n",
    "Xb, Yb = load_data('data_b.txt')\n",
    "logistic_regression(Xb, Yb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) For \"data_a\", the algorithm converged in 30380 iterations, but not converge with \"data_b\"\n",
    "\n",
    "(b) Peeking at the gradient, it goes down very slowly with more iterations\n",
    "\n",
    "(c)\\\n",
    "i. For learning rate, I think m=100 and rate=10 means $\\alpha$ = 0.1, maybe that is not a good one? Try to shift the rate into 0.2 (rate = 20) \\\n",
    "NOT WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training model on data set A ====\n",
      "Finished 10000 iterations with grad=[ 2.28046560e-12 -2.35015732e-12 -2.24377780e-12]\n",
      "Converged in 15389 iterations\n",
      "\n",
      "==== Training model on data set B ====\n",
      "Finished 10000 iterations with grad=[ 0.00012499 -0.00012488 -0.00012528]\n",
      "Finished 20000 iterations with grad=[ 7.89255821e-05 -7.90133601e-05 -7.90042257e-05]\n",
      "Finished 30000 iterations with grad=[ 5.97189140e-05 -5.98909354e-05 -5.97262845e-05]\n",
      "Finished 40000 iterations with grad=[ 4.89132458e-05 -4.91270838e-05 -4.88907259e-05]\n",
      "Finished 50000 iterations with grad=[ 4.19050009e-05 -4.21403740e-05 -4.18688337e-05]\n",
      "Finished 60000 iterations with grad=[ 3.69529650e-05 -3.71986806e-05 -3.69105829e-05]\n",
      "Finished 70000 iterations with grad=[ 3.32451560e-05 -3.34945103e-05 -3.32002969e-05]\n",
      "Finished 80000 iterations with grad=[ 3.03499960e-05 -3.05987921e-05 -3.03046491e-05]\n",
      "Finished 90000 iterations with grad=[ 2.80162822e-05 -2.82618445e-05 -2.79715356e-05]\n",
      "Finished 100000 iterations with grad=[ 2.60876233e-05 -2.63282507e-05 -2.60440708e-05]\n",
      "Finished 110000 iterations with grad=[ 2.44614449e-05 -2.46960824e-05 -2.44193978e-05]\n",
      "Finished 120000 iterations with grad=[ 2.30676034e-05 -2.32956332e-05 -2.30272068e-05]\n",
      "Finished 130000 iterations with grad=[ 2.18564597e-05 -2.20775627e-05 -2.18177595e-05]\n",
      "Finished 140000 iterations with grad=[ 2.07918613e-05 -2.10059235e-05 -2.07548442e-05]\n",
      "Finished 150000 iterations with grad=[ 1.98468264e-05 -2.00538729e-05 -1.98114444e-05]\n",
      "Finished 160000 iterations with grad=[ 1.90007873e-05 -1.92009372e-05 -1.89669726e-05]\n",
      "Finished 170000 iterations with grad=[ 1.82377744e-05 -1.84312086e-05 -1.82054494e-05]\n",
      "Finished 180000 iterations with grad=[ 1.75451855e-05 -1.77321238e-05 -1.75142683e-05]\n",
      "Finished 190000 iterations with grad=[ 1.69129317e-05 -1.70936167e-05 -1.68833402e-05]\n",
      "Finished 200000 iterations with grad=[ 1.63328318e-05 -1.65075178e-05 -1.63044858e-05]\n",
      "Finished 210000 iterations with grad=[ 1.57981747e-05 -1.59671194e-05 -1.57709971e-05]\n",
      "Finished 220000 iterations with grad=[ 1.53033976e-05 -1.54668571e-05 -1.52773156e-05]\n",
      "Finished 230000 iterations with grad=[ 1.48438461e-05 -1.50020710e-05 -1.48187911e-05]\n",
      "Finished 240000 iterations with grad=[ 1.44155922e-05 -1.45688250e-05 -1.43915002e-05]\n",
      "Finished 250000 iterations with grad=[ 1.40152952e-05 -1.41637689e-05 -1.39921065e-05]\n",
      "Finished 260000 iterations with grad=[ 1.36400931e-05 -1.37840306e-05 -1.36177524e-05]\n",
      "Finished 270000 iterations with grad=[ 1.32875182e-05 -1.34271313e-05 -1.32659741e-05]\n",
      "Finished 280000 iterations with grad=[ 1.29554297e-05 -1.30909196e-05 -1.29346346e-05]\n",
      "Finished 290000 iterations with grad=[ 1.26419600e-05 -1.27735170e-05 -1.26218698e-05]\n",
      "Finished 300000 iterations with grad=[ 1.23454713e-05 -1.24732754e-05 -1.23260452e-05]\n",
      "Finished 310000 iterations with grad=[ 1.20645206e-05 -1.21887418e-05 -1.20457209e-05]\n",
      "Finished 320000 iterations with grad=[ 1.17978308e-05 -1.19186293e-05 -1.17796224e-05]\n",
      "Finished 330000 iterations with grad=[ 1.15442667e-05 -1.16617937e-05 -1.15266173e-05]\n",
      "Finished 340000 iterations with grad=[ 1.13028156e-05 -1.14172136e-05 -1.12856950e-05]\n",
      "Finished 350000 iterations with grad=[ 1.10725706e-05 -1.11839739e-05 -1.10559508e-05]\n",
      "Finished 360000 iterations with grad=[ 1.08527167e-05 -1.09612522e-05 -1.08365718e-05]\n",
      "Finished 370000 iterations with grad=[ 1.06425194e-05 -1.07483066e-05 -1.06268252e-05]\n",
      "Finished 380000 iterations with grad=[ 1.04413145e-05 -1.05444663e-05 -1.04260486e-05]\n",
      "Finished 390000 iterations with grad=[ 1.02484998e-05 -1.03491227e-05 -1.02336412e-05]\n",
      "Finished 400000 iterations with grad=[ 1.00635279e-05 -1.01617224e-05 -1.00490570e-05]\n",
      "Finished 410000 iterations with grad=[ 9.88589963e-06 -9.98176089e-06 -9.87179822e-06]\n",
      "Finished 420000 iterations with grad=[ 9.71515907e-06 -9.80877698e-06 -9.70141006e-06]\n",
      "Finished 430000 iterations with grad=[ 9.55088869e-06 -9.64234831e-06 -9.53747608e-06]\n",
      "Finished 440000 iterations with grad=[ 9.39270528e-06 -9.48208715e-06 -9.37961410e-06]\n",
      "Finished 450000 iterations with grad=[ 9.24025644e-06 -9.32763687e-06 -9.22747264e-06]\n",
      "Finished 460000 iterations with grad=[ 9.09321745e-06 -9.17866878e-06 -9.08072787e-06]\n",
      "Finished 470000 iterations with grad=[ 8.95128856e-06 -9.03487942e-06 -8.93908079e-06]\n",
      "Finished 480000 iterations with grad=[ 8.81419254e-06 -8.89598807e-06 -8.80225494e-06]\n",
      "Finished 490000 iterations with grad=[ 8.68167258e-06 -8.76173468e-06 -8.66999418e-06]\n",
      "Finished 500000 iterations with grad=[ 8.55349039e-06 -8.63187788e-06 -8.54206085e-06]\n",
      "Finished 510000 iterations with grad=[ 8.42942452e-06 -8.50619335e-06 -8.41823409e-06]\n",
      "Finished 520000 iterations with grad=[ 8.30926886e-06 -8.38447230e-06 -8.29830833e-06]\n",
      "Finished 530000 iterations with grad=[ 8.19283130e-06 -8.26652009e-06 -8.18209198e-06]\n",
      "Finished 540000 iterations with grad=[ 8.07993255e-06 -8.15215503e-06 -8.06940620e-06]\n",
      "Finished 550000 iterations with grad=[ 7.97040504e-06 -8.04120732e-06 -7.96008388e-06]\n",
      "Finished 560000 iterations with grad=[ 7.86409198e-06 -7.93351806e-06 -7.85396863e-06]\n",
      "Finished 570000 iterations with grad=[ 7.76084647e-06 -7.82893836e-06 -7.75091392e-06]\n",
      "Finished 580000 iterations with grad=[ 7.66053070e-06 -7.72732856e-06 -7.65078232e-06]\n",
      "Finished 590000 iterations with grad=[ 7.56301529e-06 -7.62855749e-06 -7.55344478e-06]\n",
      "Finished 600000 iterations with grad=[ 7.46817860e-06 -7.53250185e-06 -7.45877995e-06]\n",
      "Finished 610000 iterations with grad=[ 7.37590615e-06 -7.43904558e-06 -7.36667368e-06]\n",
      "Finished 620000 iterations with grad=[ 7.28609011e-06 -7.34807938e-06 -7.27701839e-06]\n",
      "Finished 630000 iterations with grad=[ 7.19862880e-06 -7.25950015e-06 -7.18971266e-06]\n",
      "Finished 640000 iterations with grad=[ 7.11342624e-06 -7.17321059e-06 -7.10466075e-06]\n",
      "Finished 650000 iterations with grad=[ 7.03039177e-06 -7.08911876e-06 -7.02177224e-06]\n",
      "Finished 660000 iterations with grad=[ 6.94943965e-06 -7.00713776e-06 -6.94096161e-06]\n",
      "Finished 670000 iterations with grad=[ 6.87048876e-06 -6.92718531e-06 -6.86214792e-06]\n",
      "Finished 680000 iterations with grad=[ 6.79346226e-06 -6.84918350e-06 -6.78525452e-06]\n",
      "Finished 690000 iterations with grad=[ 6.71828730e-06 -6.77305847e-06 -6.71020876e-06]\n",
      "Finished 700000 iterations with grad=[ 6.64489478e-06 -6.69874015e-06 -6.63694169e-06]\n",
      "Finished 710000 iterations with grad=[ 6.57321910e-06 -6.62616201e-06 -6.56538787e-06]\n",
      "Finished 720000 iterations with grad=[ 6.50319792e-06 -6.55526086e-06 -6.49548513e-06]\n",
      "Finished 730000 iterations with grad=[ 6.43477199e-06 -6.48597660e-06 -6.42717435e-06]\n",
      "Finished 740000 iterations with grad=[ 6.36788493e-06 -6.41825207e-06 -6.36039928e-06]\n",
      "Finished 750000 iterations with grad=[ 6.30248305e-06 -6.35203282e-06 -6.29510637e-06]\n",
      "Finished 760000 iterations with grad=[ 6.23851522e-06 -6.28726700e-06 -6.23124460e-06]\n",
      "Finished 770000 iterations with grad=[ 6.17593269e-06 -6.22390517e-06 -6.16876534e-06]\n",
      "Finished 780000 iterations with grad=[ 6.11468894e-06 -6.16190017e-06 -6.10762218e-06]\n",
      "Finished 790000 iterations with grad=[ 6.05473959e-06 -6.10120700e-06 -6.04777084e-06]\n",
      "Finished 800000 iterations with grad=[ 5.99604225e-06 -6.04178267e-06 -5.98916903e-06]\n",
      "Finished 810000 iterations with grad=[ 5.93855641e-06 -5.98358609e-06 -5.93177633e-06]\n",
      "Finished 820000 iterations with grad=[ 5.88224333e-06 -5.92657800e-06 -5.87555409e-06]\n",
      "Finished 830000 iterations with grad=[ 5.82706596e-06 -5.87072081e-06 -5.82046535e-06]\n",
      "Finished 840000 iterations with grad=[ 5.77298883e-06 -5.81597857e-06 -5.76647472e-06]\n",
      "Finished 850000 iterations with grad=[ 5.71997798e-06 -5.76231683e-06 -5.71354830e-06]\n",
      "Finished 860000 iterations with grad=[ 5.66800086e-06 -5.70970260e-06 -5.66165364e-06]\n",
      "Finished 870000 iterations with grad=[ 5.61702628e-06 -5.65810423e-06 -5.61075959e-06]\n",
      "Finished 880000 iterations with grad=[ 5.56702430e-06 -5.60749140e-06 -5.56083631e-06]\n",
      "Finished 890000 iterations with grad=[ 5.51796623e-06 -5.55783499e-06 -5.51185515e-06]\n",
      "Finished 900000 iterations with grad=[ 5.46982449e-06 -5.50910705e-06 -5.46378860e-06]\n",
      "Finished 910000 iterations with grad=[ 5.42257263e-06 -5.46128074e-06 -5.41661024e-06]\n",
      "Finished 920000 iterations with grad=[ 5.37618519e-06 -5.41433028e-06 -5.37029471e-06]\n",
      "Finished 930000 iterations with grad=[ 5.33063773e-06 -5.36823087e-06 -5.32481761e-06]\n",
      "Finished 940000 iterations with grad=[ 5.28590674e-06 -5.32295868e-06 -5.28015546e-06]\n",
      "Finished 950000 iterations with grad=[ 5.24196960e-06 -5.27849076e-06 -5.23628570e-06]\n",
      "Finished 960000 iterations with grad=[ 5.19880454e-06 -5.23480506e-06 -5.19318660e-06]\n",
      "Finished 970000 iterations with grad=[ 5.15639058e-06 -5.19188031e-06 -5.15083724e-06]\n",
      "Finished 980000 iterations with grad=[ 5.11470755e-06 -5.14969604e-06 -5.10921748e-06]\n",
      "Finished 990000 iterations with grad=[ 5.07373598e-06 -5.10823254e-06 -5.06830790e-06]\n",
      "Finished 1000000 iterations with grad=[ 5.03345712e-06 -5.06747078e-06 -5.02808979e-06]\n",
      "Finished 1010000 iterations with grad=[ 4.99385288e-06 -5.02739244e-06 -4.98854509e-06]\n",
      "Finished 1020000 iterations with grad=[ 4.95490583e-06 -4.98797983e-06 -4.94965640e-06]\n",
      "Finished 1030000 iterations with grad=[ 4.91659912e-06 -4.94921588e-06 -4.91140692e-06]\n",
      "Finished 1040000 iterations with grad=[ 4.87891651e-06 -4.91108412e-06 -4.87378043e-06]\n",
      "Finished 1050000 iterations with grad=[ 4.84184230e-06 -4.87356865e-06 -4.83676128e-06]\n",
      "Finished 1060000 iterations with grad=[ 4.80536134e-06 -4.83665410e-06 -4.80033433e-06]\n",
      "Finished 1070000 iterations with grad=[ 4.76945898e-06 -4.80032563e-06 -4.76448497e-06]\n",
      "Finished 1080000 iterations with grad=[ 4.73412107e-06 -4.76456889e-06 -4.72919908e-06]\n",
      "Finished 1090000 iterations with grad=[ 4.69933392e-06 -4.72937000e-06 -4.69446299e-06]\n",
      "Finished 1100000 iterations with grad=[ 4.66508429e-06 -4.69471555e-06 -4.66026349e-06]\n",
      "Finished 1110000 iterations with grad=[ 4.63135938e-06 -4.66059255e-06 -4.62658780e-06]\n",
      "Finished 1120000 iterations with grad=[ 4.59814679e-06 -4.62698845e-06 -4.59342356e-06]\n",
      "Finished 1130000 iterations with grad=[ 4.56543452e-06 -4.59389109e-06 -4.56075879e-06]\n",
      "Finished 1140000 iterations with grad=[ 4.53321096e-06 -4.56128869e-06 -4.52858190e-06]\n",
      "Finished 1150000 iterations with grad=[ 4.50146486e-06 -4.52916986e-06 -4.49688165e-06]\n",
      "Finished 1160000 iterations with grad=[ 4.47018532e-06 -4.49752353e-06 -4.46564717e-06]\n",
      "Finished 1170000 iterations with grad=[ 4.43936177e-06 -4.46633901e-06 -4.43486792e-06]\n",
      "Finished 1180000 iterations with grad=[ 4.40898397e-06 -4.43560592e-06 -4.40453367e-06]\n",
      "Finished 1190000 iterations with grad=[ 4.37904200e-06 -4.40531419e-06 -4.37463451e-06]\n",
      "Finished 1200000 iterations with grad=[ 4.34952623e-06 -4.37545407e-06 -4.34516084e-06]\n",
      "Finished 1210000 iterations with grad=[ 4.32042730e-06 -4.34601610e-06 -4.31610332e-06]\n",
      "Finished 1220000 iterations with grad=[ 4.29173617e-06 -4.31699108e-06 -4.28745292e-06]\n",
      "Finished 1230000 iterations with grad=[ 4.26344403e-06 -4.28837010e-06 -4.25920086e-06]\n",
      "Finished 1240000 iterations with grad=[ 4.23554234e-06 -4.26014452e-06 -4.23133860e-06]\n",
      "Finished 1250000 iterations with grad=[ 4.20802281e-06 -4.23230591e-06 -4.20385787e-06]\n",
      "Finished 1260000 iterations with grad=[ 4.18087738e-06 -4.20484613e-06 -4.17675063e-06]\n",
      "Finished 1270000 iterations with grad=[ 4.15409823e-06 -4.17775724e-06 -4.15000908e-06]\n",
      "Finished 1280000 iterations with grad=[ 4.12767776e-06 -4.15103154e-06 -4.12362561e-06]\n",
      "Finished 1290000 iterations with grad=[ 4.10160857e-06 -4.12466154e-06 -4.09759287e-06]\n",
      "Finished 1300000 iterations with grad=[ 4.07588348e-06 -4.09863996e-06 -4.07190366e-06]\n",
      "Finished 1310000 iterations with grad=[ 4.05049552e-06 -4.07295973e-06 -4.04655103e-06]\n",
      "Finished 1320000 iterations with grad=[ 4.02543787e-06 -4.04761396e-06 -4.02152819e-06]\n",
      "Finished 1330000 iterations with grad=[ 4.00070394e-06 -4.02259595e-06 -3.99682854e-06]\n",
      "Finished 1340000 iterations with grad=[ 3.97628729e-06 -3.99789920e-06 -3.97244567e-06]\n",
      "Finished 1350000 iterations with grad=[ 3.95218168e-06 -3.97351736e-06 -3.94837334e-06]\n",
      "Finished 1360000 iterations with grad=[ 3.92838100e-06 -3.94944427e-06 -3.92460545e-06]\n",
      "Finished 1370000 iterations with grad=[ 3.90487934e-06 -3.92567392e-06 -3.90113611e-06]\n",
      "Finished 1380000 iterations with grad=[ 3.88167091e-06 -3.90220046e-06 -3.87795954e-06]\n",
      "Finished 1390000 iterations with grad=[ 3.85875010e-06 -3.87901819e-06 -3.85507013e-06]\n",
      "Finished 1400000 iterations with grad=[ 3.83611143e-06 -3.85612157e-06 -3.83246242e-06]\n",
      "Finished 1410000 iterations with grad=[ 3.81374957e-06 -3.83350520e-06 -3.81013108e-06]\n",
      "Finished 1420000 iterations with grad=[ 3.79165932e-06 -3.81116380e-06 -3.78807092e-06]\n",
      "Finished 1430000 iterations with grad=[ 3.76983560e-06 -3.78909225e-06 -3.76627688e-06]\n",
      "Finished 1440000 iterations with grad=[ 3.74827349e-06 -3.76728554e-06 -3.74474404e-06]\n",
      "Finished 1450000 iterations with grad=[ 3.72696817e-06 -3.74573879e-06 -3.72346759e-06]\n",
      "Finished 1460000 iterations with grad=[ 3.70591494e-06 -3.72444726e-06 -3.70244283e-06]\n",
      "Finished 1470000 iterations with grad=[ 3.68510922e-06 -3.70340629e-06 -3.68166521e-06]\n",
      "Finished 1480000 iterations with grad=[ 3.66454655e-06 -3.68261137e-06 -3.66113026e-06]\n",
      "Finished 1490000 iterations with grad=[ 3.64422257e-06 -3.66205808e-06 -3.64083363e-06]\n",
      "Finished 1500000 iterations with grad=[ 3.62413302e-06 -3.64174212e-06 -3.62077107e-06]\n",
      "Finished 1510000 iterations with grad=[ 3.60427377e-06 -3.62165928e-06 -3.60093845e-06]\n",
      "Finished 1520000 iterations with grad=[ 3.58464075e-06 -3.60180546e-06 -3.58133172e-06]\n",
      "Finished 1530000 iterations with grad=[ 3.56523001e-06 -3.58217665e-06 -3.56194693e-06]\n",
      "Finished 1540000 iterations with grad=[ 3.54603769e-06 -3.56276895e-06 -3.54278023e-06]\n",
      "Finished 1550000 iterations with grad=[ 3.52706003e-06 -3.54357854e-06 -3.52382785e-06]\n",
      "Finished 1560000 iterations with grad=[ 3.50829334e-06 -3.52460168e-06 -3.50508613e-06]\n",
      "Finished 1570000 iterations with grad=[ 3.48973402e-06 -3.50583474e-06 -3.48655146e-06]\n",
      "Finished 1580000 iterations with grad=[ 3.47137856e-06 -3.48727416e-06 -3.46822035e-06]\n",
      "Finished 1590000 iterations with grad=[ 3.45322353e-06 -3.46891645e-06 -3.45008935e-06]\n",
      "Finished 1600000 iterations with grad=[ 3.43526557e-06 -3.45075823e-06 -3.43215514e-06]\n",
      "Finished 1610000 iterations with grad=[ 3.41750140e-06 -3.43279616e-06 -3.41441442e-06]\n",
      "Finished 1620000 iterations with grad=[ 3.39992781e-06 -3.41502701e-06 -3.39686400e-06]\n",
      "Finished 1630000 iterations with grad=[ 3.38254168e-06 -3.39744759e-06 -3.37950075e-06]\n",
      "Finished 1640000 iterations with grad=[ 3.36533994e-06 -3.38005482e-06 -3.36232162e-06]\n",
      "Finished 1650000 iterations with grad=[ 3.34831958e-06 -3.36284564e-06 -3.34532360e-06]\n",
      "Finished 1660000 iterations with grad=[ 3.33147769e-06 -3.34581710e-06 -3.32850378e-06]\n",
      "Finished 1670000 iterations with grad=[ 3.31481139e-06 -3.32896629e-06 -3.31185930e-06]\n",
      "Finished 1680000 iterations with grad=[ 3.29831788e-06 -3.31229037e-06 -3.29538734e-06]\n",
      "Finished 1690000 iterations with grad=[ 3.28199441e-06 -3.29578656e-06 -3.27908518e-06]\n",
      "Finished 1700000 iterations with grad=[ 3.26583830e-06 -3.27945214e-06 -3.26295012e-06]\n",
      "Finished 1710000 iterations with grad=[ 3.24984693e-06 -3.26328446e-06 -3.24697956e-06]\n",
      "Finished 1720000 iterations with grad=[ 3.23401771e-06 -3.24728090e-06 -3.23117091e-06]\n",
      "Finished 1730000 iterations with grad=[ 3.21834813e-06 -3.23143892e-06 -3.21552167e-06]\n",
      "Finished 1740000 iterations with grad=[ 3.20283573e-06 -3.21575602e-06 -3.20002938e-06]\n",
      "Finished 1750000 iterations with grad=[ 3.18747809e-06 -3.20022975e-06 -3.18469162e-06]\n",
      "Finished 1760000 iterations with grad=[ 3.17227285e-06 -3.18485773e-06 -3.16950603e-06]\n",
      "Finished 1770000 iterations with grad=[ 3.15721770e-06 -3.16963761e-06 -3.15447031e-06]\n",
      "Finished 1780000 iterations with grad=[ 3.14231035e-06 -3.15456709e-06 -3.13958219e-06]\n",
      "Finished 1790000 iterations with grad=[ 3.12754860e-06 -3.13964393e-06 -3.12483944e-06]\n",
      "Finished 1800000 iterations with grad=[ 3.11293027e-06 -3.12486592e-06 -3.11023991e-06]\n",
      "Finished 1810000 iterations with grad=[ 3.09845323e-06 -3.11023090e-06 -3.09578146e-06]\n",
      "Finished 1820000 iterations with grad=[ 3.08411538e-06 -3.09573675e-06 -3.08146200e-06]\n",
      "Finished 1830000 iterations with grad=[ 3.06991468e-06 -3.08138141e-06 -3.06727949e-06]\n",
      "Finished 1840000 iterations with grad=[ 3.05584912e-06 -3.06716284e-06 -3.05323193e-06]\n",
      "Finished 1850000 iterations with grad=[ 3.04191673e-06 -3.05307905e-06 -3.03931735e-06]\n",
      "Finished 1860000 iterations with grad=[ 3.02811559e-06 -3.03912809e-06 -3.02553382e-06]\n",
      "Finished 1870000 iterations with grad=[ 3.01444381e-06 -3.02530804e-06 -3.01187946e-06]\n",
      "Finished 1880000 iterations with grad=[ 3.00089952e-06 -3.01161702e-06 -2.99835242e-06]\n",
      "Finished 1890000 iterations with grad=[ 2.98748091e-06 -2.99805320e-06 -2.98495088e-06]\n",
      "Finished 1900000 iterations with grad=[ 2.97418620e-06 -2.98461476e-06 -2.97167306e-06]\n",
      "Finished 1910000 iterations with grad=[ 2.96101364e-06 -2.97129994e-06 -2.95851721e-06]\n",
      "Finished 1920000 iterations with grad=[ 2.94796151e-06 -2.95810700e-06 -2.94548162e-06]\n",
      "Finished 1930000 iterations with grad=[ 2.93502814e-06 -2.94503424e-06 -2.93256461e-06]\n",
      "Finished 1940000 iterations with grad=[ 2.92221185e-06 -2.93207998e-06 -2.91976453e-06]\n",
      "Finished 1950000 iterations with grad=[ 2.90951105e-06 -2.91924259e-06 -2.90707976e-06]\n",
      "Finished 1960000 iterations with grad=[ 2.89692413e-06 -2.90652045e-06 -2.89450872e-06]\n",
      "Finished 1970000 iterations with grad=[ 2.88444954e-06 -2.89391198e-06 -2.88204984e-06]\n",
      "Finished 1980000 iterations with grad=[ 2.87208574e-06 -2.88141563e-06 -2.86970160e-06]\n",
      "Finished 1990000 iterations with grad=[ 2.85983123e-06 -2.86902989e-06 -2.85746249e-06]\n",
      "Finished 2000000 iterations with grad=[ 2.84768453e-06 -2.85675325e-06 -2.84533104e-06]\n",
      "After 2000000 iterations, the algorithm still not converge!\n"
     ]
    }
   ],
   "source": [
    "print('==== Training model on data set A ====')\n",
    "Xa, Ya = load_data('data_a.txt')\n",
    "logistic_regression(Xa, Ya, 20)\n",
    "\n",
    "print('\\n==== Training model on data set B ====')\n",
    "Xb, Yb = load_data('data_b.txt')\n",
    "logistic_regression(Xb, Yb, 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Decrease the learning rate over time, multiply the rate with $\\frac{1}{t^2}$ \\\n",
    "NOT WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training model on data set A ====\n",
      "Finished 10000 iterations with grad=[ 4.15154546e-08 -4.27822247e-08 -4.08456455e-08]\n",
      "Finished 20000 iterations with grad=[ 3.06367605e-12 -3.15717618e-12 -3.01431651e-12]\n",
      "Finished 30000 iterations with grad=[ 2.01423176e-16 -2.86463533e-16 -1.89141759e-16]\n",
      "Converged in 30380 iterations\n",
      "\n",
      "==== Training model on data set B ====\n",
      "Finished 10000 iterations with grad=[ 0.00019399 -0.00019355 -0.00019461]\n",
      "Finished 20000 iterations with grad=[ 0.00012541 -0.00012529 -0.0001257 ]\n",
      "Finished 30000 iterations with grad=[ 9.60445104e-05 -9.60553587e-05 -9.61981110e-05]\n",
      "Finished 40000 iterations with grad=[ 7.90651647e-05 -7.91523106e-05 -7.91443884e-05]\n",
      "Finished 50000 iterations with grad=[ 6.78328688e-05 -6.79700947e-05 -6.78680755e-05]\n",
      "Finished 60000 iterations with grad=[ 5.97905761e-05 -5.99622968e-05 -5.97981756e-05]\n",
      "Finished 70000 iterations with grad=[ 5.37193268e-05 -5.39154728e-05 -5.37089335e-05]\n",
      "Finished 80000 iterations with grad=[ 4.89573832e-05 -4.91710659e-05 -4.89349658e-05]\n",
      "Finished 90000 iterations with grad=[ 4.51121714e-05 -4.53384732e-05 -4.50816023e-05]\n",
      "Finished 100000 iterations with grad=[ 4.19351585e-05 -4.21704526e-05 -4.18990387e-05]\n",
      "Finished 110000 iterations with grad=[ 3.92609485e-05 -3.95024927e-05 -3.92210742e-05]\n",
      "Finished 120000 iterations with grad=[ 3.69750168e-05 -3.72206979e-05 -3.69326555e-05]\n",
      "Finished 130000 iterations with grad=[ 3.49954536e-05 -3.52436199e-05 -3.49515156e-05]\n",
      "Finished 140000 iterations with grad=[ 3.32620741e-05 -3.35114213e-05 -3.32172218e-05]\n",
      "Finished 150000 iterations with grad=[ 3.17296345e-05 -3.19791254e-05 -3.16843546e-05]\n",
      "Finished 160000 iterations with grad=[ 3.03634490e-05 -3.06122555e-05 -3.03181014e-05]\n",
      "Finished 170000 iterations with grad=[ 2.91364685e-05 -2.93839282e-05 -2.90913200e-05]\n",
      "Finished 180000 iterations with grad=[ 2.80272810e-05 -2.82728648e-05 -2.79825294e-05]\n",
      "Finished 190000 iterations with grad=[ 2.70187108e-05 -2.72619975e-05 -2.69745020e-05]\n",
      "Finished 200000 iterations with grad=[ 2.60968164e-05 -2.63374724e-05 -2.60532566e-05]\n",
      "Finished 210000 iterations with grad=[ 2.52501600e-05 -2.54879241e-05 -2.52073258e-05]\n",
      "Finished 220000 iterations with grad=[ 2.44692680e-05 -2.47039383e-05 -2.44272125e-05]\n",
      "Finished 230000 iterations with grad=[ 2.37462239e-05 -2.39776478e-05 -2.37049827e-05]\n",
      "Finished 240000 iterations with grad=[ 2.30743602e-05 -2.33024253e-05 -2.30339548e-05]\n",
      "Finished 250000 iterations with grad=[ 2.24480194e-05 -2.26726471e-05 -2.24084608e-05]\n",
      "Finished 260000 iterations with grad=[ 2.18623687e-05 -2.20835083e-05 -2.18236597e-05]\n",
      "Finished 270000 iterations with grad=[ 2.13132541e-05 -2.15308777e-05 -2.12753909e-05]\n",
      "Finished 280000 iterations with grad=[ 2.07970840e-05 -2.10111828e-05 -2.07600582e-05]\n",
      "Finished 290000 iterations with grad=[ 2.03107365e-05 -2.05213175e-05 -2.02745359e-05]\n",
      "Finished 300000 iterations with grad=[ 1.98514844e-05 -2.00585672e-05 -1.98160940e-05]\n",
      "Finished 310000 iterations with grad=[ 1.94169339e-05 -1.96205487e-05 -1.93823366e-05]\n",
      "Finished 320000 iterations with grad=[ 1.90049745e-05 -1.92051600e-05 -1.89711519e-05]\n",
      "Finished 330000 iterations with grad=[ 1.86137381e-05 -1.88105397e-05 -1.85806706e-05]\n",
      "Finished 340000 iterations with grad=[ 1.82415643e-05 -1.84350330e-05 -1.82092317e-05]\n",
      "Finished 350000 iterations with grad=[ 1.78869723e-05 -1.80771632e-05 -1.78553542e-05]\n",
      "Finished 360000 iterations with grad=[ 1.75486366e-05 -1.77356081e-05 -1.75177123e-05]\n",
      "Finished 370000 iterations with grad=[ 1.72253669e-05 -1.74091799e-05 -1.71951158e-05]\n",
      "Finished 380000 iterations with grad=[ 1.69160910e-05 -1.70968081e-05 -1.68864929e-05]\n",
      "Finished 390000 iterations with grad=[ 1.66198405e-05 -1.67975252e-05 -1.65908751e-05]\n",
      "Finished 400000 iterations with grad=[ 1.63357379e-05 -1.65104545e-05 -1.63073855e-05]\n",
      "Finished 410000 iterations with grad=[ 1.60629860e-05 -1.62347992e-05 -1.60352275e-05]\n",
      "Finished 420000 iterations with grad=[ 1.58008592e-05 -1.59698333e-05 -1.57736757e-05]\n",
      "Finished 430000 iterations with grad=[ 1.55486949e-05 -1.57148940e-05 -1.55220682e-05]\n",
      "Finished 440000 iterations with grad=[ 1.53058870e-05 -1.54693745e-05 -1.52797994e-05]\n",
      "Finished 450000 iterations with grad=[ 1.50718797e-05 -1.52327185e-05 -1.50463141e-05]\n",
      "Finished 460000 iterations with grad=[ 1.48461625e-05 -1.50044142e-05 -1.48211024e-05]\n",
      "Finished 470000 iterations with grad=[ 1.46282654e-05 -1.47839906e-05 -1.46036946e-05]\n",
      "Finished 480000 iterations with grad=[ 1.44177546e-05 -1.45710129e-05 -1.43936578e-05]\n",
      "Finished 490000 iterations with grad=[ 1.42142296e-05 -1.43650793e-05 -1.41905918e-05]\n",
      "Finished 500000 iterations with grad=[ 1.40173196e-05 -1.41658177e-05 -1.39941264e-05]\n",
      "Finished 510000 iterations with grad=[ 1.38266806e-05 -1.39728828e-05 -1.38039182e-05]\n",
      "Finished 520000 iterations with grad=[ 1.36419934e-05 -1.37859540e-05 -1.36196483e-05]\n",
      "Finished 530000 iterations with grad=[ 1.34629608e-05 -1.36047329e-05 -1.34410204e-05]\n",
      "Finished 540000 iterations with grad=[ 1.32893063e-05 -1.34289415e-05 -1.32677581e-05]\n",
      "Finished 550000 iterations with grad=[ 1.31207717e-05 -1.32583203e-05 -1.30996038e-05]\n",
      "Finished 560000 iterations with grad=[ 1.29571159e-05 -1.30926269e-05 -1.29363170e-05]\n",
      "Finished 570000 iterations with grad=[ 1.27981136e-05 -1.29316345e-05 -1.27776725e-05]\n",
      "Finished 580000 iterations with grad=[ 1.26435535e-05 -1.27751306e-05 -1.26234597e-05]\n",
      "Finished 590000 iterations with grad=[ 1.24932376e-05 -1.26229160e-05 -1.24734809e-05]\n",
      "Finished 600000 iterations with grad=[ 1.23469801e-05 -1.24748034e-05 -1.23275506e-05]\n",
      "Finished 610000 iterations with grad=[ 1.22046063e-05 -1.23306170e-05 -1.21854946e-05]\n",
      "Finished 620000 iterations with grad=[ 1.20659518e-05 -1.21901913e-05 -1.20471489e-05]\n",
      "Finished 630000 iterations with grad=[ 1.19308619e-05 -1.20533701e-05 -1.19123589e-05]\n",
      "Finished 640000 iterations with grad=[ 1.17991906e-05 -1.19200066e-05 -1.17809792e-05]\n",
      "Finished 650000 iterations with grad=[ 1.16708003e-05 -1.17899617e-05 -1.16528723e-05]\n",
      "Finished 660000 iterations with grad=[ 1.15455607e-05 -1.16631044e-05 -1.15279084e-05]\n",
      "Finished 670000 iterations with grad=[ 1.14233491e-05 -1.15393106e-05 -1.14059649e-05]\n",
      "Finished 680000 iterations with grad=[ 1.13040488e-05 -1.14184628e-05 -1.12869255e-05]\n",
      "Finished 690000 iterations with grad=[ 1.11875498e-05 -1.13004498e-05 -1.11706803e-05]\n",
      "Finished 700000 iterations with grad=[ 1.10737475e-05 -1.11851662e-05 -1.10571251e-05]\n",
      "Finished 710000 iterations with grad=[ 1.09625427e-05 -1.10725118e-05 -1.09461610e-05]\n",
      "Finished 720000 iterations with grad=[ 1.08538413e-05 -1.09623915e-05 -1.08376940e-05]\n",
      "Finished 730000 iterations with grad=[ 1.07475539e-05 -1.08547151e-05 -1.07316349e-05]\n",
      "Finished 740000 iterations with grad=[ 1.06435953e-05 -1.07493967e-05 -1.06278989e-05]\n",
      "Finished 750000 iterations with grad=[ 1.05418848e-05 -1.06463544e-05 -1.05264052e-05]\n",
      "Finished 760000 iterations with grad=[ 1.04423451e-05 -1.05455105e-05 -1.04270771e-05]\n",
      "Finished 770000 iterations with grad=[ 1.03449029e-05 -1.04467906e-05 -1.03298411e-05]\n",
      "Finished 780000 iterations with grad=[ 1.02494881e-05 -1.03501240e-05 -1.02346274e-05]\n",
      "Finished 790000 iterations with grad=[ 1.01560339e-05 -1.02554431e-05 -1.01413695e-05]\n",
      "Finished 800000 iterations with grad=[ 1.00644766e-05 -1.01626836e-05 -1.00500037e-05]\n",
      "Finished 810000 iterations with grad=[ 9.97475505e-06 -1.00717836e-05 -9.96046918e-06]\n",
      "Finished 820000 iterations with grad=[ 9.88681115e-06 -9.98268441e-06 -9.87270785e-06]\n",
      "Finished 830000 iterations with grad=[ 9.80058915e-06 -9.89532957e-06 -9.78666416e-06]\n",
      "Finished 840000 iterations with grad=[ 9.71603573e-06 -9.80966518e-06 -9.70228491e-06]\n",
      "Finished 850000 iterations with grad=[ 9.63309984e-06 -9.72563958e-06 -9.61951920e-06]\n",
      "Finished 860000 iterations with grad=[ 9.55173257e-06 -9.64320330e-06 -9.53831824e-06]\n",
      "Finished 870000 iterations with grad=[ 9.47188704e-06 -9.56230889e-06 -9.45863527e-06]\n",
      "Finished 880000 iterations with grad=[ 9.39351830e-06 -9.48291087e-06 -9.38042547e-06]\n",
      "Finished 890000 iterations with grad=[ 9.31658321e-06 -9.40496557e-06 -9.30364581e-06]\n",
      "Finished 900000 iterations with grad=[ 9.24104036e-06 -9.32843110e-06 -9.22825499e-06]\n",
      "Finished 910000 iterations with grad=[ 9.16685000e-06 -9.25326719e-06 -9.15421336e-06]\n",
      "Finished 920000 iterations with grad=[ 9.09397391e-06 -9.17943517e-06 -9.08148281e-06]\n",
      "Finished 930000 iterations with grad=[ 9.02237536e-06 -9.10689786e-06 -9.01002671e-06]\n",
      "Finished 940000 iterations with grad=[ 8.95201905e-06 -9.03561949e-06 -8.93980984e-06]\n",
      "Finished 950000 iterations with grad=[ 8.88287098e-06 -8.96556566e-06 -8.87079830e-06]\n",
      "Finished 960000 iterations with grad=[ 8.81489845e-06 -8.89670324e-06 -8.80295947e-06]\n",
      "Finished 970000 iterations with grad=[ 8.74806998e-06 -8.82900035e-06 -8.73626195e-06]\n",
      "Finished 980000 iterations with grad=[ 8.68235521e-06 -8.76242625e-06 -8.67067548e-06]\n",
      "Finished 990000 iterations with grad=[ 8.61772493e-06 -8.69695134e-06 -8.60617091e-06]\n",
      "Finished 1000000 iterations with grad=[ 8.55415094e-06 -8.63254707e-06 -8.54272013e-06]\n",
      "Finished 1010000 iterations with grad=[ 8.49160607e-06 -8.56918590e-06 -8.48029602e-06]\n",
      "Finished 1020000 iterations with grad=[ 8.43006410e-06 -8.50684129e-06 -8.41887245e-06]\n",
      "Finished 1030000 iterations with grad=[ 8.36949972e-06 -8.44548758e-06 -8.35842416e-06]\n",
      "Finished 1040000 iterations with grad=[ 8.30988851e-06 -8.38510004e-06 -8.29892680e-06]\n",
      "Finished 1050000 iterations with grad=[ 8.25120686e-06 -8.32565474e-06 -8.24035684e-06]\n",
      "Finished 1060000 iterations with grad=[ 8.19343199e-06 -8.26712860e-06 -8.18269153e-06]\n",
      "Finished 1070000 iterations with grad=[ 8.13654186e-06 -8.20949929e-06 -8.12590891e-06]\n",
      "Finished 1080000 iterations with grad=[ 8.08051519e-06 -8.15274524e-06 -8.06998774e-06]\n",
      "Finished 1090000 iterations with grad=[ 8.02533136e-06 -8.09684557e-06 -8.01490748e-06]\n",
      "Finished 1100000 iterations with grad=[ 7.97097047e-06 -8.04178009e-06 -7.96064825e-06]\n",
      "Finished 1110000 iterations with grad=[ 7.91741323e-06 -7.98752926e-06 -7.90719083e-06]\n",
      "Finished 1120000 iterations with grad=[ 7.86464099e-06 -7.93407418e-06 -7.85451662e-06]\n",
      "Finished 1130000 iterations with grad=[ 7.81263568e-06 -7.88139654e-06 -7.80260758e-06]\n",
      "Finished 1140000 iterations with grad=[ 7.76137980e-06 -7.82947860e-06 -7.75144627e-06]\n",
      "Finished 1150000 iterations with grad=[ 7.71085640e-06 -7.77830317e-06 -7.70101578e-06]\n",
      "Finished 1160000 iterations with grad=[ 7.66104906e-06 -7.72785361e-06 -7.65129973e-06]\n",
      "Finished 1170000 iterations with grad=[ 7.61194184e-06 -7.67811377e-06 -7.60228223e-06]\n",
      "Finished 1180000 iterations with grad=[ 7.56351932e-06 -7.62906802e-06 -7.55394789e-06]\n",
      "Finished 1190000 iterations with grad=[ 7.51576653e-06 -7.58070116e-06 -7.50628178e-06]\n",
      "Finished 1200000 iterations with grad=[ 7.46866893e-06 -7.53299848e-06 -7.45926940e-06]\n",
      "Finished 1210000 iterations with grad=[ 7.42221243e-06 -7.48594569e-06 -7.41289669e-06]\n",
      "Finished 1220000 iterations with grad=[ 7.37638335e-06 -7.43952891e-06 -7.36715002e-06]\n",
      "Finished 1230000 iterations with grad=[ 7.33116842e-06 -7.39373469e-06 -7.32201614e-06]\n",
      "Finished 1240000 iterations with grad=[ 7.28655473e-06 -7.34854996e-06 -7.27748218e-06]\n",
      "Finished 1250000 iterations with grad=[ 7.24252977e-06 -7.30396201e-06 -7.23353565e-06]\n",
      "Finished 1260000 iterations with grad=[ 7.19908135e-06 -7.25995850e-06 -7.19016441e-06]\n",
      "Finished 1270000 iterations with grad=[ 7.15619767e-06 -7.21652745e-06 -7.14735667e-06]\n",
      "Finished 1280000 iterations with grad=[ 7.11386722e-06 -7.17365720e-06 -7.10510096e-06]\n",
      "Finished 1290000 iterations with grad=[ 7.07207883e-06 -7.13133643e-06 -7.06338613e-06]\n",
      "Finished 1300000 iterations with grad=[ 7.03082163e-06 -7.08955411e-06 -7.02220136e-06]\n",
      "Finished 1310000 iterations with grad=[ 6.99008506e-06 -7.04829953e-06 -6.98153608e-06]\n",
      "Finished 1320000 iterations with grad=[ 6.94985884e-06 -7.00756228e-06 -6.94138006e-06]\n",
      "Finished 1330000 iterations with grad=[ 6.91013296e-06 -6.96733220e-06 -6.90172332e-06]\n",
      "Finished 1340000 iterations with grad=[ 6.87089768e-06 -6.92759942e-06 -6.86255613e-06]\n",
      "Finished 1350000 iterations with grad=[ 6.83214354e-06 -6.88835434e-06 -6.82386905e-06]\n",
      "Finished 1360000 iterations with grad=[ 6.79386131e-06 -6.84958760e-06 -6.78565288e-06]\n",
      "Finished 1370000 iterations with grad=[ 6.75604199e-06 -6.81129009e-06 -6.74789865e-06]\n",
      "Finished 1380000 iterations with grad=[ 6.71867684e-06 -6.77345293e-06 -6.71059763e-06]\n",
      "Finished 1390000 iterations with grad=[ 6.68175733e-06 -6.73606749e-06 -6.67374131e-06]\n",
      "Finished 1400000 iterations with grad=[ 6.64527517e-06 -6.69912533e-06 -6.63732142e-06]\n",
      "Finished 1410000 iterations with grad=[ 6.60922224e-06 -6.66261826e-06 -6.60132988e-06]\n",
      "Finished 1420000 iterations with grad=[ 6.57359066e-06 -6.62653826e-06 -6.56575881e-06]\n",
      "Finished 1430000 iterations with grad=[ 6.53837274e-06 -6.59087754e-06 -6.53060054e-06]\n",
      "Finished 1440000 iterations with grad=[ 6.50356098e-06 -6.55562849e-06 -6.49584758e-06]\n",
      "Finished 1450000 iterations with grad=[ 6.46914807e-06 -6.52078370e-06 -6.46149265e-06]\n",
      "Finished 1460000 iterations with grad=[ 6.43512685e-06 -6.48633592e-06 -6.42752862e-06]\n",
      "Finished 1470000 iterations with grad=[ 6.40149039e-06 -6.45227811e-06 -6.39394855e-06]\n",
      "Finished 1480000 iterations with grad=[ 6.36823188e-06 -6.41860337e-06 -6.36074566e-06]\n",
      "Finished 1490000 iterations with grad=[ 6.33534469e-06 -6.38530497e-06 -6.32791333e-06]\n",
      "Finished 1500000 iterations with grad=[ 6.30282236e-06 -6.35237637e-06 -6.29544512e-06]\n",
      "Finished 1510000 iterations with grad=[ 6.27065857e-06 -6.31981116e-06 -6.26333473e-06]\n",
      "Finished 1520000 iterations with grad=[ 6.23884716e-06 -6.28760308e-06 -6.23157599e-06]\n",
      "Finished 1530000 iterations with grad=[ 6.20738209e-06 -6.25574602e-06 -6.20016291e-06]\n",
      "Finished 1540000 iterations with grad=[ 6.17625749e-06 -6.22423402e-06 -6.16908961e-06]\n",
      "Finished 1550000 iterations with grad=[ 6.14546762e-06 -6.19306126e-06 -6.13835036e-06]\n",
      "Finished 1560000 iterations with grad=[ 6.11500685e-06 -6.16222204e-06 -6.10793957e-06]\n",
      "Finished 1570000 iterations with grad=[ 6.08486971e-06 -6.13171081e-06 -6.07785176e-06]\n",
      "Finished 1580000 iterations with grad=[ 6.05505084e-06 -6.10152212e-06 -6.04808158e-06]\n",
      "Finished 1590000 iterations with grad=[ 6.02554499e-06 -6.07165066e-06 -6.01862381e-06]\n",
      "Finished 1600000 iterations with grad=[ 5.99634705e-06 -6.04209125e-06 -5.98947333e-06]\n",
      "Finished 1610000 iterations with grad=[ 5.96745201e-06 -6.01283880e-06 -5.96062516e-06]\n",
      "Finished 1620000 iterations with grad=[ 5.93885497e-06 -5.98388835e-06 -5.93207440e-06]\n",
      "Finished 1630000 iterations with grad=[ 5.91055114e-06 -5.95523504e-06 -5.90381629e-06]\n",
      "Finished 1640000 iterations with grad=[ 5.88253585e-06 -5.92687413e-06 -5.87584614e-06]\n",
      "Finished 1650000 iterations with grad=[ 5.85480450e-06 -5.89880097e-06 -5.84815938e-06]\n",
      "Finished 1660000 iterations with grad=[ 5.82735262e-06 -5.87101101e-06 -5.82075156e-06]\n",
      "Finished 1670000 iterations with grad=[ 5.80017583e-06 -5.84349982e-06 -5.79361828e-06]\n",
      "Finished 1680000 iterations with grad=[ 5.77326983e-06 -5.81626303e-06 -5.76675526e-06]\n",
      "Finished 1690000 iterations with grad=[ 5.74663041e-06 -5.78929638e-06 -5.74015833e-06]\n",
      "Finished 1700000 iterations with grad=[ 5.72025348e-06 -5.76259572e-06 -5.71382336e-06]\n",
      "Finished 1710000 iterations with grad=[ 5.69413499e-06 -5.73615695e-06 -5.68774636e-06]\n",
      "Finished 1720000 iterations with grad=[ 5.66827103e-06 -5.70997608e-06 -5.66192338e-06]\n",
      "Finished 1730000 iterations with grad=[ 5.64265771e-06 -5.68404920e-06 -5.63635057e-06]\n",
      "Finished 1740000 iterations with grad=[ 5.61729127e-06 -5.65837247e-06 -5.61102417e-06]\n",
      "Finished 1750000 iterations with grad=[ 5.59216800e-06 -5.63294215e-06 -5.58594048e-06]\n",
      "Finished 1760000 iterations with grad=[ 5.56728428e-06 -5.60775456e-06 -5.56109588e-06]\n",
      "Finished 1770000 iterations with grad=[ 5.54263655e-06 -5.58280609e-06 -5.53648683e-06]\n",
      "Finished 1780000 iterations with grad=[ 5.51822133e-06 -5.55809321e-06 -5.51210985e-06]\n",
      "Finished 1790000 iterations with grad=[ 5.49403522e-06 -5.53361247e-06 -5.48796155e-06]\n",
      "Finished 1800000 iterations with grad=[ 5.47007487e-06 -5.50936048e-06 -5.46403858e-06]\n",
      "Finished 1810000 iterations with grad=[ 5.44633700e-06 -5.48533391e-06 -5.44033768e-06]\n",
      "Finished 1820000 iterations with grad=[ 5.42281841e-06 -5.46152951e-06 -5.41685564e-06]\n",
      "Finished 1830000 iterations with grad=[ 5.39951594e-06 -5.43794410e-06 -5.39358933e-06]\n",
      "Finished 1840000 iterations with grad=[ 5.37642651e-06 -5.41457453e-06 -5.37053566e-06]\n",
      "Finished 1850000 iterations with grad=[ 5.35354709e-06 -5.39141774e-06 -5.34769161e-06]\n",
      "Finished 1860000 iterations with grad=[ 5.33087471e-06 -5.36847072e-06 -5.32505422e-06]\n",
      "Finished 1870000 iterations with grad=[ 5.30840647e-06 -5.34573053e-06 -5.30262059e-06]\n",
      "Finished 1880000 iterations with grad=[ 5.28613951e-06 -5.32319426e-06 -5.28038786e-06]\n",
      "Finished 1890000 iterations with grad=[ 5.26407102e-06 -5.30085907e-06 -5.25835325e-06]\n",
      "Finished 1900000 iterations with grad=[ 5.24219826e-06 -5.27872219e-06 -5.23651401e-06]\n",
      "Finished 1910000 iterations with grad=[ 5.22051854e-06 -5.25678087e-06 -5.21486745e-06]\n",
      "Finished 1920000 iterations with grad=[ 5.19902921e-06 -5.23503244e-06 -5.19341093e-06]\n",
      "Finished 1930000 iterations with grad=[ 5.17772767e-06 -5.21347427e-06 -5.17214186e-06]\n",
      "Finished 1940000 iterations with grad=[ 5.15661137e-06 -5.19210376e-06 -5.15105770e-06]\n",
      "Finished 1950000 iterations with grad=[ 5.13567782e-06 -5.17091839e-06 -5.13015595e-06]\n",
      "Finished 1960000 iterations with grad=[ 5.11492456e-06 -5.14991567e-06 -5.10943417e-06]\n",
      "Finished 1970000 iterations with grad=[ 5.09434918e-06 -5.12909315e-06 -5.08888994e-06]\n",
      "Finished 1980000 iterations with grad=[ 5.07394931e-06 -5.10844844e-06 -5.06852092e-06]\n",
      "Finished 1990000 iterations with grad=[ 5.05372264e-06 -5.08797917e-06 -5.04832477e-06]\n",
      "Finished 2000000 iterations with grad=[ 5.03366687e-06 -5.06768305e-06 -5.02829922e-06]\n",
      "After 2000000 iterations, the algorithm still not converge!\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_t(X, Y, rate = 10):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    learning_rate = rate\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        prev_theta = theta\n",
    "        grad = calc_grad(X, Y, theta)\n",
    "        theta = theta  - learning_rate * (1 / i*i) * (grad)\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Finished {i} iterations with grad={grad}\")\n",
    "        if np.linalg.norm(prev_theta - theta) < 1e-15:\n",
    "            print('Converged in %d iterations' % i)\n",
    "            break\n",
    "        if i > 2000000:\n",
    "            print(\"After 2000000 iterations, the algorithm still not converge!\")\n",
    "            break\n",
    "    return\n",
    "\n",
    "print('==== Training model on data set A ====')\n",
    "logistic_regression_t(Xa, Ya)\n",
    "\n",
    "print('\\n==== Training model on data set B ====')\n",
    "logistic_regression_t(Xb, Yb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Adding a regularization term $\\|\\theta\\|_2^2$ to the loss function \\\n",
    "WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training model on data set A ====\n",
      "Converged in 7229 iterations\n",
      "\n",
      "==== Training model on data set B ====\n",
      "Finished 10000 iterations with grad=[ 1.02673946e-15 -8.90997345e-16 -9.52363188e-16]\n",
      "Converged in 10801 iterations\n"
     ]
    }
   ],
   "source": [
    "def calc_grad_r(X, Y, theta, r = 0.01):\n",
    "    m, n = X.shape\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    margins = Y * X.dot(theta)\n",
    "    probs = 1. / (1 + np.exp(margins))\n",
    "    grad = -(1./m) * (X.T.dot(probs * Y)) + r * (1./m) * theta\n",
    "\n",
    "    return grad\n",
    "\n",
    "def logistic_regression_r(X, Y, rate = 10):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    learning_rate = rate\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        prev_theta = theta\n",
    "        grad = calc_grad_r(X, Y, theta)\n",
    "        theta = theta  - learning_rate * (grad) \n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Finished {i} iterations with grad={grad}\")\n",
    "        if np.linalg.norm(prev_theta - theta) < 1e-15:\n",
    "            print('Converged in %d iterations' % i)\n",
    "            break\n",
    "        if i > 2000000:\n",
    "            print(\"After 2000000 iterations, the algorithm still not converge!\")\n",
    "            break\n",
    "    return\n",
    "\n",
    "print('==== Training model on data set A ====')\n",
    "logistic_regression_r(Xa, Ya)\n",
    "\n",
    "print('\\n==== Training model on data set B ====')\n",
    "logistic_regression_r(Xb, Yb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Linear scaling of the input features \\\n",
    "NOT WORK, because it does not affect the calculation of gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training model on data set A ====\n",
      "Finished 10000 iterations with grad=[-0.09106724 -0.36539725 -0.55611922]\n",
      "Finished 20000 iterations with grad=[-0.08232607 -0.33781042 -0.48451258]\n",
      "Finished 30000 iterations with grad=[-0.0824997  -0.30831575 -0.52215135]\n",
      "Finished 40000 iterations with grad=[-0.10718074 -0.45478757 -0.64377839]\n",
      "Finished 50000 iterations with grad=[-0.08259839 -0.32095127 -0.50800366]\n",
      "Finished 60000 iterations with grad=[-0.10739315 -0.45600711 -0.64489189]\n",
      "Finished 70000 iterations with grad=[-0.09068532 -0.3515836  -0.56798646]\n",
      "Finished 80000 iterations with grad=[-0.09891643 -0.40400647 -0.60457759]\n",
      "Finished 90000 iterations with grad=[-0.0787289  -0.3179119  -0.46540736]\n",
      "Finished 100000 iterations with grad=[-0.07879712 -0.3184274  -0.46559362]\n",
      "Finished 110000 iterations with grad=[-0.08427112 -0.34291669 -0.5016497 ]\n",
      "Finished 120000 iterations with grad=[-0.08971974 -0.35398147 -0.55346373]\n",
      "Finished 130000 iterations with grad=[-0.09152527 -0.35806073 -0.57026801]\n",
      "Finished 140000 iterations with grad=[-0.09173035 -0.36620413 -0.56305848]\n",
      "Finished 150000 iterations with grad=[-0.07572551 -0.29147777 -0.46149024]\n",
      "Finished 160000 iterations with grad=[-0.0799474  -0.32628785 -0.46980274]\n",
      "Finished 170000 iterations with grad=[-0.08965129 -0.34447015 -0.56411882]\n",
      "Finished 180000 iterations with grad=[-0.10715625 -0.4547926  -0.64347402]\n",
      "Finished 190000 iterations with grad=[-0.09180666 -0.36219559 -0.56867641]\n",
      "Finished 200000 iterations with grad=[-0.09053572 -0.34917495 -0.5692052 ]\n",
      "Finished 210000 iterations with grad=[-0.10848494 -0.46221339 -0.6506925 ]\n",
      "Finished 220000 iterations with grad=[-0.09175636 -0.36203595 -0.56826221]\n",
      "Finished 230000 iterations with grad=[-0.0963978  -0.38747998 -0.59397434]\n",
      "Finished 240000 iterations with grad=[-0.09098521 -0.3537073  -0.56904649]\n",
      "Finished 250000 iterations with grad=[-0.10830416 -0.46115923 -0.64976453]\n",
      "Finished 260000 iterations with grad=[-0.09149496 -0.36123698 -0.56607694]\n",
      "Finished 270000 iterations with grad=[-0.09442539 -0.37704996 -0.58251094]\n",
      "Finished 280000 iterations with grad=[-0.09156635 -0.36145052 -0.56667877]\n",
      "Finished 290000 iterations with grad=[-0.0918079  -0.36128425 -0.56978521]\n",
      "Finished 300000 iterations with grad=[-0.09146853 -0.36115875 -0.56585336]\n",
      "Finished 310000 iterations with grad=[-0.09053465 -0.35045665 -0.56753493]\n",
      "Finished 320000 iterations with grad=[-0.08057587 -0.33073487 -0.47199469]\n",
      "Finished 330000 iterations with grad=[-0.0907917  -0.35236385 -0.56832486]\n",
      "Finished 340000 iterations with grad=[-0.09109837 -0.35282534 -0.57161049]\n",
      "Finished 350000 iterations with grad=[-0.09210356 -0.36327514 -0.57096345]\n",
      "Finished 360000 iterations with grad=[-0.08465787 -0.31566339 -0.53907801]\n",
      "Finished 370000 iterations with grad=[-0.09068337 -0.35898073 -0.55905104]\n",
      "Finished 380000 iterations with grad=[-0.08224383 -0.33738429 -0.48403439]\n",
      "Finished 390000 iterations with grad=[-0.0943192  -0.37474736 -0.58408263]\n",
      "Finished 400000 iterations with grad=[-0.08230566 -0.33258626 -0.49044603]\n",
      "Finished 410000 iterations with grad=[-0.09163184 -0.36164932 -0.56722761]\n",
      "Finished 420000 iterations with grad=[-0.09166259 -0.36174372 -0.56748426]\n",
      "Finished 430000 iterations with grad=[-0.09626803 -0.38665406 -0.5933963 ]\n",
      "Finished 440000 iterations with grad=[-0.10618793 -0.4490501  -0.63862024]\n",
      "Finished 450000 iterations with grad=[-0.07918013 -0.32122181 -0.46675692]\n",
      "Finished 460000 iterations with grad=[-0.09165189 -0.36171081 -0.56739506]\n",
      "Finished 470000 iterations with grad=[-0.10879318 -0.46401005 -0.65227591]\n",
      "Finished 480000 iterations with grad=[-0.10732778 -0.45563142 -0.64454968]\n",
      "Finished 490000 iterations with grad=[-0.09153376 -0.36135265 -0.56640449]\n",
      "Finished 500000 iterations with grad=[-0.09586747 -0.38417633 -0.59152047]\n",
      "Finished 510000 iterations with grad=[-0.09293584 -0.36736937 -0.57611517]\n",
      "Finished 520000 iterations with grad=[-0.07605347 -0.28750712 -0.47023871]\n",
      "Finished 530000 iterations with grad=[-0.08619296 -0.34962976 -0.51663153]\n",
      "Finished 540000 iterations with grad=[-0.09124647 -0.36051657 -0.56395788]\n",
      "Finished 550000 iterations with grad=[-0.09150928 -0.36127956 -0.56619793]\n",
      "Finished 560000 iterations with grad=[-0.08573316 -0.32615836 -0.53922577]\n",
      "Finished 570000 iterations with grad=[-0.09493216 -0.3787837  -0.58663874]\n",
      "Finished 580000 iterations with grad=[-0.08313997 -0.34085473 -0.49062268]\n",
      "Finished 590000 iterations with grad=[-0.09189445 -0.36207283 -0.56988244]\n",
      "Finished 600000 iterations with grad=[-0.08358374 -0.33624114 -0.50133895]\n",
      "Finished 610000 iterations with grad=[-0.09186453 -0.36172149 -0.5699432 ]\n",
      "Finished 620000 iterations with grad=[-0.09186239 -0.36237506 -0.56913267]\n",
      "Finished 630000 iterations with grad=[-0.09183572 -0.36228884 -0.56891473]\n",
      "Finished 640000 iterations with grad=[-0.08646806 -0.32672185 -0.54734848]\n",
      "Finished 650000 iterations with grad=[-0.0822522  -0.33664505 -0.48500066]\n",
      "Finished 660000 iterations with grad=[-0.08161038 -0.33540756 -0.47881812]\n",
      "Finished 670000 iterations with grad=[-0.09194135 -0.36233899 -0.57012886]\n",
      "Finished 680000 iterations with grad=[-0.09166537 -0.36046626 -0.56904708]\n",
      "Finished 690000 iterations with grad=[-0.09829891 -0.39947285 -0.60258343]\n",
      "Finished 700000 iterations with grad=[-0.10727592 -0.45533357 -0.64427797]\n",
      "Finished 710000 iterations with grad=[-0.08712339 -0.33830344 -0.54117145]\n",
      "Finished 720000 iterations with grad=[-0.08004467 -0.32781441 -0.46911506]\n",
      "Finished 730000 iterations with grad=[-0.09233077 -0.36323489 -0.57378048]\n",
      "Finished 740000 iterations with grad=[-0.07880391 -0.31845875 -0.46563448]\n",
      "Finished 750000 iterations with grad=[-0.09026799 -0.35790059 -0.5553738 ]\n",
      "Finished 760000 iterations with grad=[-0.08733294 -0.35006623 -0.52966373]\n",
      "Finished 770000 iterations with grad=[-0.09086907 -0.35947554 -0.56068204]\n",
      "Finished 780000 iterations with grad=[-0.091294   -0.36065189 -0.56436589]\n",
      "Finished 790000 iterations with grad=[-0.09327623 -0.37135154 -0.57544964]\n",
      "Finished 800000 iterations with grad=[-0.09082443 -0.35231915 -0.56879359]\n",
      "Finished 810000 iterations with grad=[-0.10866393 -0.46324846 -0.65162206]\n",
      "Finished 820000 iterations with grad=[-0.07895992 -0.31963179 -0.46606743]\n",
      "Finished 830000 iterations with grad=[-0.08940323 -0.34649664 -0.55861656]\n",
      "Finished 840000 iterations with grad=[-0.09182266 -0.36224684 -0.56880773]\n",
      "Finished 850000 iterations with grad=[-0.0962021  -0.38691216 -0.5922391 ]\n",
      "Finished 860000 iterations with grad=[-0.08092208 -0.33145163 -0.4752819 ]\n",
      "Finished 870000 iterations with grad=[-0.09766468 -0.39617967 -0.5988145 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m==== Training model on data set A ====\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m Xa, Ya \u001b[39m=\u001b[39m load_data_s(\u001b[39m'\u001b[39m\u001b[39mdata_a.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m logistic_regression(Xa, Ya)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m==== Training model on data set B ====\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m Xb, Yb \u001b[39m=\u001b[39m load_data_s(\u001b[39m'\u001b[39m\u001b[39mdata_b.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb Cell 11\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(X, Y, rate)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m prev_theta \u001b[39m=\u001b[39m theta\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m grad \u001b[39m=\u001b[39m calc_grad(X, Y, theta)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m theta \u001b[39m=\u001b[39m theta  \u001b[39m-\u001b[39m learning_rate \u001b[39m*\u001b[39m (grad)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m10000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb Cell 11\u001b[0m in \u001b[0;36mcalc_grad\u001b[0;34m(X, Y, theta)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m m, n \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m grad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(theta\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m margins \u001b[39m=\u001b[39m Y \u001b[39m*\u001b[39m X\u001b[39m.\u001b[39;49mdot(theta)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m probs \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mexp(margins))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shenqingyun/Desktop/git_repository/CS229_code/ps2/task1.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m grad \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m(\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39mm) \u001b[39m*\u001b[39m (X\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(probs \u001b[39m*\u001b[39m Y))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def add_intercept_s(X_, scale = 10):\n",
    "    m, n = X_.shape\n",
    "    X = np.zeros((m, n + 1))\n",
    "    X[:, 0] = 1\n",
    "    X[:, 1:] = scale * X_\n",
    "    return X\n",
    "\n",
    "def load_data_s(filename):\n",
    "    D = np.loadtxt(filename)\n",
    "    Y = D[:, 0]\n",
    "    X = D[:, 1:]\n",
    "    return add_intercept_s(X), Y\n",
    "\n",
    "print('==== Training model on data set A ====')\n",
    "Xa, Ya = load_data_s('data_a.txt')\n",
    "logistic_regression(Xa, Ya)\n",
    "\n",
    "print('\\n==== Training model on data set B ====')\n",
    "Xb, Yb = load_data_s('data_b.txt')\n",
    "logistic_regression(Xb, Yb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Add zero-mean Gaussion noise to the training data \\\n",
    "WORKS!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training model on data set A ====\n",
      "Converged in 8150 iterations\n",
      "\n",
      "==== Training model on data set B ====\n",
      "Finished 10000 iterations with grad=[ 1.03784736e-11 -9.55528430e-12 -1.12971925e-11]\n",
      "Converged in 16338 iterations\n"
     ]
    }
   ],
   "source": [
    "def load_data_g(filename):\n",
    "    D = np.loadtxt(filename)\n",
    "    Y = D[:, 0]\n",
    "    X = D[:, 1:]\n",
    "\n",
    "    noise_matrix_x = np.random.normal(0, 0.1, X.shape)\n",
    "    return add_intercept(X + noise_matrix_x), Y\n",
    "\n",
    "print('==== Training model on data set A ====')\n",
    "Xa, Ya = load_data_g('data_a.txt')\n",
    "logistic_regression(Xa, Ya)\n",
    "\n",
    "print('\\n==== Training model on data set B ====')\n",
    "Xb, Yb = load_data_g('data_b.txt')\n",
    "logistic_regression(Xb, Yb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Are SVM vulnerable to datasets like b? \\\n",
    "First we visualize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(filename):\n",
    "    data = np.loadtxt(filename)\n",
    "\n",
    "    data_neg = data[data[:, 0] == -1]\n",
    "    data_pos = data[data[:, 0] == 1]\n",
    "\n",
    "    plt.scatter(data_neg[:, 1], data_neg[:, 2], color=\"red\", marker=\"o\", label=\"-1\")\n",
    "    plt.scatter(data_pos[:, 1], data_pos[:, 2], color=\"blue\", marker=\"s\", label=\"1\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(\"data_a.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(\"data_b.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that data_a is linearly inseparable but data_b is linearly separable, so when we train logistic regression, the decision boundary keeps moving inside the \"gap\" but converge with data_a. But when we train SVM, the boundary should be only a definitive one "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntroDase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
